{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size=5> <b> SMU Homewwork 4 - MSDS7337 - Natural Language Processing </b> </font>\n",
    "<br><br><br>\n",
    "<center><font size=4> <b> Spring 2021  Ikenna Nwaogu </b></font> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://cdn.searchenginejournal.com/wp-content/uploads/2020/08/an-introduction-to-natural-language-processing-with-python-for-seos-5f3519eeb8368-760x400.webp\"> \n",
    "<br>\n",
    "<p align=\"center\"><font size=4> <b><center> Part of Speech(POS) Tagger  </b></font> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK N-Gram Tagging\n",
    "\n",
    "We trained a unigram tagger using the nltk brown corpus with tags. Because we have to learn from a pre-tag corpus for the unigram, it would perform poorly if the sentence used to be used is not contained in the pre-tagged corpus or if the sentence is of different category as the pre-tagged corpus. The word defence, Messi, Madrid, Sergio, Ramos werent present in the tagged corpus so the tagger couldn't tag it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lionel', 'NP'),\n",
       " ('Messi', None),\n",
       " ('dribbled', 'VBD'),\n",
       " ('the', 'AT'),\n",
       " ('ball', 'NN'),\n",
       " ('past', 'NN'),\n",
       " ('the', 'AT'),\n",
       " ('Real', 'JJ-TL'),\n",
       " ('Madrid', 'NP'),\n",
       " ('defence', None),\n",
       " ('even', 'RB'),\n",
       " ('though', 'CS'),\n",
       " ('that', 'CS'),\n",
       " ('Sergio', None),\n",
       " ('Ramos', None),\n",
       " ('was', 'BEDZ'),\n",
       " ('present', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('defence', None)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents()\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "sentence = 'Lionel Messi dribbled the ball past the Real Madrid defence even though that Sergio Ramos was present in the defence'\n",
    "\n",
    "#clean string\n",
    "pat = re.compile(r'[^a-zA-Z ]+')\n",
    "sentence = re.sub(pat, '', sentence)\n",
    "\n",
    "#split string\n",
    "splits = sentence.split()\n",
    "\n",
    "unigram_tagger.tag(splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from nltk.tokenize.stanford import StanfordTokenizer\n",
    ">>> s = \"Good muffins cost $3.88\\nin New York.  Please buy me\\ntwo of them.\\nThanks.\"\n",
    ">>> StanfordTokenizer().tokenize(s)\n",
    ">>> s = \"The colour of the wall is blue.\"\n",
    ">>> StanfordTokenizer(options={\"americanize\": True}).tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html\n",
      "    xmlns:og=\"http://ogp.me/ns#\"\n",
      "    xmlns:fb=\"http://www.facebook.com/2008/fbml\">\n",
      "    <head>\n",
      "         \n",
      "        <meta charset=\"utf-8\">\n",
      "        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "\n",
      "    <meta name=\"ap\n"
     ]
    }
   ],
   "source": [
    "from requests import get\n",
    "url = 'https://www.imdb.com/title/tt1439629/episodes?season=1'\n",
    "response = get(url)\n",
    "print(response.text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Lionel/NNP\n",
      "  Messi/NNP\n",
      "  dribbled/VBD\n",
      "  (NP the/DT ball/NN)\n",
      "  past/IN\n",
      "  the/DT\n",
      "  Real/NNP\n",
      "  Madrid/NNP\n",
      "  (NP defence/NN)\n",
      "  even/RB\n",
      "  though/IN\n",
      "  that/DT\n",
      "  Sergio/NNP\n",
      "  Ramos/NNP\n",
      "  was/VBD\n",
      "  present/JJ\n",
      "  in/IN\n",
      "  (NP the/DT defence/NN))\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "text = nltk.word_tokenize(sentence)\n",
    "text = nltk.pos_tag(text)\n",
    "result = cp.parse(text)\n",
    "print(result)\n",
    "result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lionel Messi dribbled the ball past the Real Madrid defence even though that Sergio Ramos was present in the defence\n"
     ]
    }
   ],
   "source": [
    "def ie_preprocess(document):\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    \n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Unigram with shorter sentence\n",
    "This was a bit easier for the tagger because the sentence is short and it also has the words in tagged in the training Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'PPS'), ('spoke', 'VBD'), ('English', 'JJ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceShort = 'She spoke English.'\n",
    "\n",
    "#clean string\n",
    "pat = re.compile(r'[^a-zA-Z ]+')\n",
    "sentenceShort = re.sub(pat, '', sentenceShort)\n",
    "\n",
    "#split string\n",
    "splitsShort = sentenceShort.split()\n",
    "\n",
    "unigram_tagger.tag(splitsShort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running a different POS Tagger\n",
    "##### Using NTLK pos_tag\n",
    "Using the regular pos_tagger in NTLK, the tagger performed much better than the unigram tagger. They certainly did not produce the same tagger for the sentnce. This is because as stated above the unigram learns from a tagged corpus given to it as opposed to a generalized and more complex tagger. I think it is case sensitive so that it coud detect a potential 'NNP'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lionel', 'NNP'),\n",
       " ('Messi', 'NNP'),\n",
       " ('dribbled', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('ball', 'NN'),\n",
       " ('past', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Real', 'NNP'),\n",
       " ('Madrid', 'NNP'),\n",
       " ('defence', 'NN'),\n",
       " ('even', 'RB'),\n",
       " ('though', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('Sergio', 'NNP'),\n",
       " ('Ramos', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('present', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('defence', 'NN')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(sentence)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. POS Tagger vs Manually generated\n",
    "##### Using NTLK pos_tag\n",
    "Using the regular pos_tagger in NTLK, we compared it's tagging with the manual generated ones from a random sentence from AP news. \n",
    "I attempted manually assigning POS tags for the sentence and compared it to the one created by the NTLK POS tager and one created by the unigram tagger. <br>My ManualPOS tag was as follows: <br><br>\n",
    "[('The', 'DT'),\n",
    " ('former', 'JJ'),\n",
    " ('president', 'NN'),\n",
    " ('a', 'DT'),\n",
    " ('Republican', 'NNP'),\n",
    " ('has', 'VBN'),\n",
    " ('argued', 'VBN'),\n",
    " ('for', 'IN'),\n",
    " ('years', 'NNS'),\n",
    " ('that', 'UH'),\n",
    " ('he', 'PRP'),\n",
    " ('broke', 'VBG'),\n",
    " ('no', 'DT'),\n",
    " ('laws', 'NNS'),\n",
    " ('and', 'UH'),\n",
    " ('has', 'VBN'),\n",
    " ('been', 'VBN'),\n",
    " ('unfairly', 'RB'),\n",
    " ('targeted', 'VBD'),\n",
    " ('by', 'IN'),\n",
    " ('Democrats', 'NNS'),\n",
    " ('for', 'IN'),\n",
    " ('political', 'JJ'),\n",
    " ('reasons', 'NNS')] \n",
    " <br><br> The pos_tag function of the NLTK package was comparable to my manually tagged output. I might have not tagged the sentence better than I should but I was quite surprise how close they were. The unigram tagger did ok but didn't tag the word 'targeted'; this is simply because the word was not in the trained corpus(pre-tagged). I believe the unigram tagger performed better than it did in the previous sentence because it was trained using news corpus(pre-tagged)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('former', 'JJ'),\n",
       " ('president', 'NN'),\n",
       " (',', ','),\n",
       " ('a', 'DT'),\n",
       " ('Republican', 'NNP'),\n",
       " (',', ','),\n",
       " ('has', 'VBZ'),\n",
       " ('argued', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('years', 'NNS'),\n",
       " ('that', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('broke', 'VBD'),\n",
       " ('no', 'DT'),\n",
       " ('laws', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('unfairly', 'RB'),\n",
       " ('targeted', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('Democrats', 'NNPS'),\n",
       " ('for', 'IN'),\n",
       " ('political', 'JJ'),\n",
       " ('reasons', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceAP = 'The former president, a Republican, has argued for years that he broke no laws and has been unfairly targeted by Democrats for political reasons.'\n",
    "text = nltk.word_tokenize(sentenceAP)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('former', 'AP'),\n",
       " ('president', 'NN'),\n",
       " (',', ','),\n",
       " ('a', 'AT'),\n",
       " ('Republican', 'NP'),\n",
       " (',', ','),\n",
       " ('has', 'HVZ'),\n",
       " ('argued', 'VBD'),\n",
       " ('for', 'IN'),\n",
       " ('years', 'NNS'),\n",
       " ('that', 'CS'),\n",
       " ('he', 'PPS'),\n",
       " ('broke', 'VBD'),\n",
       " ('no', 'AT'),\n",
       " ('laws', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('has', 'HVZ'),\n",
       " ('been', 'BEN'),\n",
       " ('unfairly', 'RB'),\n",
       " ('targeted', None),\n",
       " ('by', 'IN'),\n",
       " ('Democrats', 'NPS'),\n",
       " ('for', 'IN'),\n",
       " ('political', 'JJ'),\n",
       " ('reasons', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I booked a flight from LA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.word_tokenize(sentence)\n",
    "h = nltk.pos_tag(text)\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "grammar = r\"\"\"\n",
    "  NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "      {<NNP>+}                # chunk sequences of proper nouns\n",
    "\"\"\"\n",
    "\n",
    "grammar = \"NP: {<NN><NN>}  # Chunk two consecutive nouns\"\n",
    "grammar = r\"NP: {<[CDJNP].*>+}\"\n",
    "#grammar = r\"NP: {<DT>?<VP>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "# cp = nltk.RegexpParser('CHUNK: {<V.*> <TO> <V.*>}')\n",
    "result = cp.parse(h)\n",
    "result.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
