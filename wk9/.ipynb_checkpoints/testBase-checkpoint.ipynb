{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size=5> <b> SMU Homewwork 5 - MSDS7337 - Natural Language Processing </b> </font>\n",
    "<br><br><br>\n",
    "<center><font size=4> <b> Spring 2021  Ikenna Nwaogu </b></font> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://cdn.searchenginejournal.com/wp-content/uploads/2020/08/an-introduction-to-natural-language-processing-with-python-for-seos-5f3519eeb8368-760x400.webp\"> \n",
    "<br>\n",
    "<p align=\"center\"><font size=4> <b><center> IMDB Movie Review Tokenization  </b></font> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK N-Gram Tagging\n",
    "\n",
    "We trained a unigram tagger using the nltk brown corpus with tags. Because we have to learn from a pre-tag corpus for the unigram, it would perform poorly if the sentence used to be used is not contained in the pre-tagged corpus or if the sentence is of different category as the pre-tagged corpus. The word defence, Messi, Madrid, Sergio, Ramos werent present in the tagged corpus so the tagger couldn't tag it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I bought this on VHS as \"Terror Hospital\", and when I got home I checked IMDb and was like OMG it\\'s the legendary \"Nurse Sherri\"!!! So here\\'s another one from Al Adamson, who had clearly learned some minuscule amount about film-making since the \"Blood of Dracula\\'s Castle\" days. Where that earlier effort is a more or less totally sclerotic lump, this one mixes it up a little, adding a definite element of variety and surprise amid the incompetence. Sure half of the movie is a blind post-op football player shooting the breeze with his stacked nurse, but at any moment we might be cutting away to the cackling disembodied head of the satanist mastermind, or Nurse Sherri running a farmer through with a pitchfork, or a wee bit of abstract student-film quick cutting to go with the pulsing-blob effects in the possession scene, or the most gratuitously half-hearted topless bit ever, or god knows what else (I forget, to be honest). As dumb-ass pieces of sh*t go, this one runs toward the high end. Congrats, Al.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "import os     \n",
    "\n",
    "path = \"./MovieDataset/\"\n",
    "all_files = os.listdir(path)  \n",
    "\n",
    "for i in all_files:\n",
    "    with open(path + i, 'rt') as fd:\n",
    "        print(fd.readlines())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-44a8843a62bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwebsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.imdb.com/title/tt7349950/reviews?ref_=tt_urv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwebsite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "website = requests.get('https://www.imdb.com/title/tt7349950/reviews?ref_=tt_urv')\n",
    "soup = BeautifulSoup(website.content, 'html.parser')\n",
    "tags = soup.find_all(['a', 'h2', 'title'])\n",
    "for soups in tags:\n",
    "    print(soups.string)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Unigram with shorter sentence\n",
    "This was a bit easier for the tagger because the sentence is short and it also has the words in tagged in the training Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'PPS'), ('spoke', 'VBD'), ('English', 'JJ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceShort = 'She spoke English.'\n",
    "\n",
    "#clean string\n",
    "pat = re.compile(r'[^a-zA-Z ]+')\n",
    "sentenceShort = re.sub(pat, '', sentenceShort)\n",
    "\n",
    "#split string\n",
    "splitsShort = sentenceShort.split()\n",
    "\n",
    "unigram_tagger.tag(splitsShort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running a different POS Tagger\n",
    "##### Using NTLK pos_tag\n",
    "Using the regular pos_tagger in NTLK, the tagger performed much better than the unigram tagger. They certainly did not produce the same tagger for the sentnce. This is because as stated above the unigram learns from a tagged corpus given to it as opposed to a generalized and more complex tagger. I think it is case sensitive so that it coud detect a potential 'NNP'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lionel', 'NNP'),\n",
       " ('Messi', 'NNP'),\n",
       " ('dribbled', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('ball', 'NN'),\n",
       " ('past', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Real', 'NNP'),\n",
       " ('Madrid', 'NNP'),\n",
       " ('defence', 'NN'),\n",
       " ('even', 'RB'),\n",
       " ('though', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('Sergio', 'NNP'),\n",
       " ('Ramos', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('present', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('defence', 'NN')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(sentence)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. POS Tagger vs Manually generated\n",
    "##### Using NTLK pos_tag\n",
    "Using the regular pos_tagger in NTLK, we compared it's tagging with the manual generated ones from a random sentence from AP news. \n",
    "I attempted manually assigning POS tags for the sentence and compared it to the one created by the NTLK POS tager and one created by the unigram tagger. <br>My ManualPOS tag was as follows: <br><br>\n",
    "[('The', 'DT'),\n",
    " ('former', 'JJ'),\n",
    " ('president', 'NN'),\n",
    " ('a', 'DT'),\n",
    " ('Republican', 'NNP'),\n",
    " ('has', 'VBN'),\n",
    " ('argued', 'VBN'),\n",
    " ('for', 'IN'),\n",
    " ('years', 'NNS'),\n",
    " ('that', 'UH'),\n",
    " ('he', 'PRP'),\n",
    " ('broke', 'VBG'),\n",
    " ('no', 'DT'),\n",
    " ('laws', 'NNS'),\n",
    " ('and', 'UH'),\n",
    " ('has', 'VBN'),\n",
    " ('been', 'VBN'),\n",
    " ('unfairly', 'RB'),\n",
    " ('targeted', 'VBD'),\n",
    " ('by', 'IN'),\n",
    " ('Democrats', 'NNS'),\n",
    " ('for', 'IN'),\n",
    " ('political', 'JJ'),\n",
    " ('reasons', 'NNS')] \n",
    " <br><br> The pos_tag function of the NLTK package was comparable to my manually tagged output. I might have not tagged the sentence better than I should but I was quite surprise how close they were. The unigram tagger did ok but didn't tag the word 'targeted'; this is simply because the word was not in the trained corpus(pre-tagged). I believe the unigram tagger performed better than it did in the previous sentence because it was trained using news corpus(pre-tagged)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('former', 'JJ'),\n",
       " ('president', 'NN'),\n",
       " (',', ','),\n",
       " ('a', 'DT'),\n",
       " ('Republican', 'NNP'),\n",
       " (',', ','),\n",
       " ('has', 'VBZ'),\n",
       " ('argued', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('years', 'NNS'),\n",
       " ('that', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('broke', 'VBD'),\n",
       " ('no', 'DT'),\n",
       " ('laws', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('unfairly', 'RB'),\n",
       " ('targeted', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('Democrats', 'NNPS'),\n",
       " ('for', 'IN'),\n",
       " ('political', 'JJ'),\n",
       " ('reasons', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceAP = 'The former president, a Republican, has argued for years that he broke no laws and has been unfairly targeted by Democrats for political reasons.'\n",
    "text = nltk.word_tokenize(sentenceAP)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('former', 'AP'),\n",
       " ('president', 'NN'),\n",
       " (',', ','),\n",
       " ('a', 'AT'),\n",
       " ('Republican', 'NP'),\n",
       " (',', ','),\n",
       " ('has', 'HVZ'),\n",
       " ('argued', 'VBD'),\n",
       " ('for', 'IN'),\n",
       " ('years', 'NNS'),\n",
       " ('that', 'CS'),\n",
       " ('he', 'PPS'),\n",
       " ('broke', 'VBD'),\n",
       " ('no', 'AT'),\n",
       " ('laws', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('has', 'HVZ'),\n",
       " ('been', 'BEN'),\n",
       " ('unfairly', 'RB'),\n",
       " ('targeted', None),\n",
       " ('by', 'IN'),\n",
       " ('Democrats', 'NPS'),\n",
       " ('for', 'IN'),\n",
       " ('political', 'JJ'),\n",
       " ('reasons', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.tag(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
